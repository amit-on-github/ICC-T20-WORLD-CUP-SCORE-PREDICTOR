{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.pipeline import Pipeline\n",
    "df=pd.read_csv('/information.csv')\n",
    "df.head()\n",
    "df.shape\n",
    "VISUALIZATION\n",
    "import plotly.express as px\n",
    "average_runs_under_pressure = df[df['pressure'] == 1].groupby('batting_team')['runs_x'].mean().reset_index()\n",
    "\n",
    "fig = px.bar(\n",
    "    data_frame=average_runs_under_pressure,\n",
    "    x='batting_team',\n",
    "    y='runs_x',\n",
    "    color='batting_team',  # Assigning different colors based on the Batting_team column\n",
    "    template='plotly_dark',\n",
    "    title='Average Runs Scored by Batting Team Under Pressure'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Batting Team',\n",
    "    yaxis_title='Average Runs'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "death_overs_runs = df[df['Death_Overs'] == 1].groupby('batting_team')['runs_x'].mean().reset_index()\n",
    "\n",
    "fig = px.bar(\n",
    "    data_frame=death_overs_runs,\n",
    "    x='batting_team',\n",
    "    y='runs_x',\n",
    "    color='batting_team',  # Assigning different colors based on the Batting_team column\n",
    "    template='plotly_dark',\n",
    "    title='Average Runs Scored by Batting Team In Death Overs'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Batting Team',\n",
    "    yaxis_title='Average Runs'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "team_counts = df['batting_team'].value_counts()\n",
    "fig = px.pie(names=team_counts.index, values=team_counts.values, title='Distribution of Batting Teams')\n",
    "fig.show()\n",
    "average_crr_pp = df.groupby('batting_team')['crr'].mean().reset_index()\n",
    "average_crr_pp = average_crr_pp.sort_values('crr', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Plot the average CRR in PP for each batting team\n",
    "fig = px.bar(average_crr_pp, x='batting_team', y='crr', title='Average CRR in Powerplay by Batting Team')\n",
    "fig.show()\n",
    "fig = px.pie(df, names='wickets_left', title='Distribution of Wickets Left')\n",
    "fig.show()\n",
    "DATA CLEANING\n",
    "So this is that dataset we have. We need to create some columns and extract few to get the desired data. Eventually we want our data to have columns:\n",
    "\n",
    "batting team\n",
    "\n",
    "bowling team\n",
    "\n",
    "city\n",
    "\n",
    "current_score\n",
    "\n",
    "balls left\n",
    "\n",
    "wickets_left\n",
    "\n",
    "current_run_rate\n",
    "\n",
    "last five\n",
    "Now we already have few columns as we want it in our dataset. Batting team and bowling team data we already have. we also have city column but it has some null values which we need to figure out how to handle that. For rest all we need do some manipulation.\n",
    "\n",
    "Now we will start our feature extraction from the city column. To fill the empty values we will use venue column.\n",
    "\n",
    "df[df['city'].isnull()]['venue'].value_counts()\n",
    "Here we are checking the values in ‘venue’ column where city column has null values. If we notice carefully the first word in venue is actually the name of the city where the venue exists for e.g. Dubai in Dubai International Cricket Stadium or Melbourne in Melbourne Cricket Ground.\n",
    "cities=np.where(df['city'].isnull(),df['venue'].str.split().apply(lambda x:x[0]),df['city'])\n",
    "df['city']=cities\n",
    "df.isnull().sum()\n",
    "So we store all the first word of venue column in variable named cities and then use it to fill the the city column. Now there are no null values in our dataset. But still there is one more thing left. Our dataset is a ball-by-ball dataset which means if there are 63000 rows that means that many balls have been bowled and played.\n",
    "df.drop(columns=['Unnamed: 0','venue'],inplace=True)\n",
    "df\n",
    "eligible_cities=df['city'].value_counts()[df['city'].value_counts()>600].index.tolist()\n",
    "This shows that there are certain cities where very few deliveries have been played. So we can ignore those cities and only consider the ones which have at least 600 deliveries.\n",
    "df=df[df['city'].isin(eligible_cities)]\n",
    "Now our city column is complete. Coming to current_runs column which is very easy to extract from the runs column. A simple cumsum() function (used to find the cumulative sum of a column) will do the work for us.\n",
    "df['current_score']=df.groupby('match_id').cumsum()['runs']\n",
    "df\n",
    "Now our next target is to create a ‘balls_left’ column for which firstly we would be creating to new columns: ‘overs’ and ‘balls’ which tells us how many overs have been completed and how many balls of the current over has been bowled respectively. The code is very simple for that.\n",
    "df['over']=df['ball'].apply(lambda x:str(x).split(\".\")[0])\n",
    "df['ball_no']=df['ball'].apply(lambda x:str(x).split(\".\")[1])\n",
    "df\n",
    "Now by using a simple formula we can create a ‘balls_bowled’ column that is how many balls have been bowled. Formula would be\n",
    "\n",
    "balls_bowled = (overs * 6) + balls\n",
    "df['balls_bowled']=(df['over'].astype('int')*6) + df['ball_no'].astype('int')\n",
    "df\n",
    "And now finally we can create our desired column ‘balls_left’ by subtracting balls_bowled from 120 because there are total 120 balls in an innings. sometimes because of extras (wide, no ball …) the ball count exceeds 120 so in such case we can simply give the value of 0.And now finally we can create our desired column ‘balls_left’ by subtracting balls_bowled from 120 because there are total 120 balls in an innings. sometimes because of extras (wide, no ball …) the ball count exceeds 120 so in such case we can simply give the value of 0.\n",
    "df['balls_left']=120-df['balls_bowled']\n",
    "df['balls_left']=df['balls_left'].apply(lambda x:0 if x<0 else x)\n",
    "df\n",
    "Now if we look at the ‘player_dismissed’ column it has either value 0 or name of the player got out at that particular ball. First we will replace all the names with 1 and then apply the cumsum() function on it so we can get the total wickets gone and we will subtract it from 10 to get the ‘wickets_left’ column.\n",
    "df['player_dismissed'] = df['player_dismissed'].apply(lambda x:0 if x=='0' else 1)\n",
    "df['player_dismissed'] = df['player_dismissed'].astype('int')\n",
    "df['player_dismissed'] = df.groupby('match_id').cumsum()['player_dismissed']\n",
    "df['wickets_left'] = 10 - df['player_dismissed']\n",
    "df\n",
    "df['crr']=(df['current_score']*6)/df['balls_bowled']\n",
    "df\n",
    "Now we need a column that has total runs scored in last five overs. Obviously we will have null values in this column for first 5 overs.\n",
    "groups=df.groupby('match_id')\n",
    "\n",
    "match_ids=df['match_id'].unique()\n",
    "last_five=[]\n",
    "for id in match_ids:\n",
    "    last_five.extend(groups.get_group(id).rolling(window=30).sum()['runs'].values.tolist())\n",
    "df['last_five']=last_five\n",
    "df\n",
    "Now we have to create a last column which would be our target column. Total runs scored in that innings.\n",
    "final_df=df.groupby('match_id').sum()['runs'].reset_index().merge(df,on='match_id')\n",
    "final_df=final_df[['batting_team','bowling_team','city','current_score','balls_left','wickets_left','crr','last_five','runs_x']]\n",
    "final_df\n",
    "Now we will drop all the columns which we dont want to have for our model and keep those which we created just now. Also we will shuffle the data to avoid any kind of bias.\n",
    "final_df.isnull().sum()\n",
    "final_df.dropna(inplace=True)\n",
    "final_df.isnull().sum()\n",
    "final_df=final_df.sample(final_df.shape[0])\n",
    "final_df\n",
    "TRAIN AND TEST DATASETS\n",
    "With this we end out feature extraction part of the project. So after lot of work we finally have the exact required data we wanted at the start.\n",
    "\n",
    "So lets now begin with model building process. For that first we will divide our dataset in training set and testing set using train_test_split module of sklearn library\n",
    "#Train-Test-Split\n",
    "\n",
    "X=final_df.drop(columns=['runs_x'])\n",
    "y=final_df['runs_x']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "X_train\n",
    "CREATING MODEL\n",
    "Some preprocessing steps are required here. We will apply one hot encoding on the categorical features (batting_team, bowling_team and city) then we will create a pipleline which would be having our ml model. Also we will apply scaling on our data so that all values come in one range.\n",
    "\n",
    "Here four our model I will be using xgboost algorithm.\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score,mean_absolute_error\n",
    "trf = ColumnTransformer([\n",
    "    ('trf',OneHotEncoder(sparse=False,drop='first'),['batting_team','bowling_team','city'])\n",
    "]\n",
    ",remainder='passthrough')\n",
    "pipe=Pipeline(steps=[\n",
    "    ('step1',trf),\n",
    "    ('step2',StandardScaler()),\n",
    "    ('step3',XGBRegressor(n_estimators=300,learning_rate=0.2,max_depth=12,random_state=1))\n",
    "\n",
    "])\n",
    "pipe.fit(X_train,Y_train)\n",
    "Y_pred=pipe.predict(X_test)\n",
    "print(r2_score(Y_test,Y_pred))\n",
    "print(mean_absolute_error(Y_test,Y_pred))\n",
    "import pickle\n",
    "pickle.dump(pipe,open('pipe.pkl','wb'))\n",
    "eligible_cities"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
